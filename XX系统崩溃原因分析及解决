XX系统崩溃原因分析及解决
—双活集群系统出现503、504错误，导致业务不可用
1、	物理架构
A、	数据层面采用两个ORACLE数据实例的RAC组织数据支持；
B、	应用层面采用两个单独物理节点TOMCAT6.x作为业务应用容器，提供服务；
C、	代理层面采用HAPROXY作为负载均衡工具，将两个TOMCAT组织为双活系统。
2、	问题出现现象
3月11日开始，系统出现服务不可用的情况，双活系统从代理层面到应用服务器都出现了503或者504的系统错误，业务无法正常运行；经过多次排查，问题也逐步演变，数据访问慢、线程池暴涨、内存溢出、以及系统指标均正常的情况下突然假死等。
3、	问题排查过程
1、	问题，表空间：3月12日至14日排查发现数据库表空间容量存在问题。
应对：增加表空间容量。
2、	问题，线程：应对1之后，系统再次出现问题，经对日志分析以及系统监控，发现线程池增加至上限且无法回收。
应对：增加线程池以及可用连接数，且对与外管系统报文交互功能代码进行排查，增强其对线程并发的控制约束。
3、	问题，内存：应对2之后，系统再次出现问题。经过申请压力测试人员对系统进行压力测试，并监控应用java虚拟机的内存，发现润前报表交易汇总表在简单的几个并发下，就会导致内存溢出；
应对：调整优化JVM内存单数，重构该报表，将该报表替换为普通的系统查询功能，内存上得到有效控制。
4、	问题，tomcat链接池：应对3之后，系统再次出现问题。系统各项监控指标（CPU、内存、线程）均在正常范围，但是系统依然会不定期出现假死现象：应用服务对外无任何响应。与此同时，第三方监控平台zabbix系统不断报出JVM内存回收的警告事件，为排查增加难度。
应对：经多次压力测试，发现内存上并没有出现任何异常现象。在压测复现问题后，发现有很多线程被DBCP链接池锁定。经过查阅资料发现，tomcat6.x的DBCP链接池上确实存在BUG，会导致应用无响应。所以，应用数据访问改为采用JDBC方式进行数据访问。系统能够保证可用性，但是其访问RAC效率低下，导致系统吞吐量降低，业务操作速度变慢。
建议策略：将tomcat6.x升级为tomcat7.x，采用7.x的连接池进行数据访问，能够增加系统吞吐量，业务响应速度大大提升。经过压测，单节点，20并发下（相当于200总用户数），连接池以及数据链接均能够稳定在一定水平，系统平稳运行。
4、	总结
本次系统从问题爆发到解决过程持续近一个月的时间。期间，经过各位专家不断地诊断、排查、应对，发现的问题错综复杂，很多层面均有问题。
a)	问题汇总
1、	原始表空间的设计直接采用system表空间，不很合理；
2、	对外管数据的报文交互上，存在线程控制上的问题；
3、	润前报表的内存分页机制，不适合于大数据量的报表展示；建议统计类型、有限条数的报表采用润前；具有明细意味，或者有不断增加数据条数的报表采用系统的查询功能方式实现；
4、	TOMCAT6.x的版本，其业务处理能力一般，其DBCP链接池上存在一定BUG，建议不采用连接池方式链接，或者升级tomcat版本。
b)	处理汇总
1、	增加表空间容量；
2、	增加对外管系统交互的线程限制；
3、	调整JVM参数，优化JVM垃圾回收效率；
4、	重构部分报表功能，用业务查询功能代替；
5、	应用取消对tomcat dbcp链接池的调用，采用单独的jdbc方式链接数据库；
6、	在tomcat7的版本下已进行过压力测试，基本性能上、可用性上均有所提升。（目前尚未在生产商部署）
c)	建议及次要因素分析
1、	网络波动：排查问题期间，部署过一个网络ping值的监控脚本，发现从应用服务器到数据服务器之间，会经常性出现短暂网络波动（超时、响应事件增加），这个问题虽然不致命，但是会影响到业务吞吐量以及业务办理的成功率。
2、	数据库及RAC尚有优化空间：在分析日志过程中，发现颇多地方出现正常的SQL执行错误，数据库日志文件、缓存等方面的问题。
3、	应用服务器：TOMCAT作为开源产品，其商务应用能力、技术支持等方面均比较薄弱，一旦出现问题，处理响应的时效性上较低。尤其6.x的版本上，本身在业界就是颇多质疑。建议能够采购合适的中间件，或者采用较高版本的TOMCAT。
4、	监控平台：ZABBIX系统中，对应用添加了很多不必要的事件触发器，导致监管平台几乎一直出现事件提示，（如，内存使用超过20%、30%、40、50%等等均会触发事件报警；线程使用超过20%、30%、40%、50%等也均会触发事件报警；GC开启火线模式、或者系统为JVM分配全额内存也会触发事件报警）建议精简一些不必要的报警，能够然我们的监控更为有效，问题排查更为高效。
